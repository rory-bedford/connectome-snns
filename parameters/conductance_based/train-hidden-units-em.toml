# Parameters for EM-like training of hidden units
# Based on train-feedforward-noisy.toml, adds EM iteration parameters

# ========================
# SIMULATION CONFIGURATION
# ========================

[simulation]
seed = 44                              # Random seed for reproducibility
chunk_size = 200                       # Number of timesteps per chunk
hidden_cell_fraction = 0.2             # Fraction of recurrent cells that are hidden

# ==============
# EM PARAMETERS
# ==============

[em]
total_iterations = 5                   # Number of EM iterations
epochs_per_update = 5                  # Epochs of feedforward training per EM step

# ======================
# TRAINING CONFIGURATION
# ======================

[training]
chunks_per_update = 5                  # Number of loss calculations per gradient step
log_interval = 5                       # Log metrics to CSV and wandb every N chunks
checkpoint_interval = 50               # Save model checkpoints and generate plots every N chunks
plot_size = 50                         # Number of chunks to accumulate for plotting (must be <= checkpoint_interval)
mixed_precision = true                 # Whether to train with mixed precision
weight_perturbation_variance = 0.0     # Variance of log-normal distribution for scaling factor perturbation
optimisable = "scaling_factors"        # What to optimize: "scaling_factors", "scaling_factors_recurrent", "scaling_factors_feedforward", "weights"
momentum = 0.6                         # Adam beta1 parameter (default 0.9, lower values = less momentum)

# ===============
# HYPERPARAMETERS
# ===============

[hyperparameters]
surrgrad_scale = 0.5                   # Scale for surrogate gradient fast sigmoid function
learning_rate = 1e-2                   # Learning rate for ADAM optimiser
van_rossum_tau_rise = 10.0             # ms - Rise time constant for van Rossum double exponential filter
van_rossum_tau_decay = 100.0           # ms - Decay time constant for van Rossum double exponential filter

loss_weight.van_rossum = 10.0          # Weight for van Rossum spike distance metric

# ==========================
# FEEDFORWARD LAYER SYNAPSES
# ==========================

[feedforward.cell_types]
names = [ "mitral",]                   # Cell type names

[feedforward.synapses.mitral]
names = [ "AMPA", "NMDA",]
tau_rise = [ 0.1, 10.0,]               # ms - Synaptic rise time constants
tau_decay = [ 5.0, 70.0,]              # ms - Synaptic decay time constants
E_syn = [ 0.0, 0.0,]                   # mV - Synaptic reversal potentials
g_bar = [ 4.177, 0.448,]               # nS - Maximum synaptic conductances

# =======================================
# RECURRENT LAYER PHYSIOLOGY AND SYNAPSES
# =======================================

[recurrent.cell_types]
names = [ "excitatory", "inhibitory",] # Cell type names

[recurrent.physiology.excitatory]
tau_mem = 85.0                         # ms - Membrane time constant
theta = -38.0                          # mV - Spike threshold voltage
U_reset = -60.0                        # mV - Reset potential after spike
E_L = -60.0                            # mV - Leak reversal potential
g_L = 1.35                             # nS - Leak conductance
tau_ref = 8.0                          # ms - Refractory period

[recurrent.synapses.excitatory]
names = [ "AMPA", "NMDA",]
tau_rise = [ 0.1, 10.0,]               # ms - Synaptic rise time constants
tau_decay = [ 5.0, 70.0,]              # ms - Synaptic decay time constants
E_syn = [ 0.0, 0.0,]                   # mV - Synaptic reversal potentials
g_bar = [ 4.177, 0.448,]               # nS - Synaptic conductances (per spike)

[recurrent.physiology.inhibitory]
tau_mem = 50.0                         # ms - Membrane time constant
theta = -45.0                          # mV - Spike threshold voltage
U_reset = -60.0                        # mV - Reset voltage after spike
E_L = -60.0                            # mV - Leak reversal potential
g_L = 0.9                              # nS - Leak conductance
tau_ref = 8.0                          # ms - Refractory period

[recurrent.synapses.inhibitory]
names = [ "GABA_A",]
tau_rise = [ 1.0,]                     # ms - Synaptic rise time constants
tau_decay = [ 6.0,]                    # ms - Synaptic decay time constants
E_syn = [ -70.0,]                      # mV - Synaptic reversal potentials
g_bar = [ 8.139,]                      # nS - Synaptic conductances (per spike)

# ========================
# SCALING FACTORS
# ========================

[scaling_factors]
recurrent = [
    [1.0, 1.0],
    [1.0, 1.0],
]

feedforward = [
    [1.0, 1.0],
]
